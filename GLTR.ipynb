{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from pytorch_pretrained_bert import (GPT2LMHeadModel, GPT2Tokenizer,\n",
    "                                     BertTokenizer, BertForMaskedLM)\n",
    "\n",
    "\n",
    "class AbstractLanguageChecker():\n",
    "    \"\"\"\n",
    "    Abstract Class that defines the Backend API of GLTR.\n",
    "\n",
    "    To extend the GLTR interface, you need to inherit this and\n",
    "    fill in the defined functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        In the subclass, you need to load all necessary components\n",
    "        for the other functions.\n",
    "        Typically, this will comprise a tokenizer and a model.\n",
    "        '''\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def check_probabilities(self, in_text, topk=40):\n",
    "        '''\n",
    "        Function that GLTR interacts with to check the probabilities of words\n",
    "\n",
    "        Params:\n",
    "        - in_text: str -- The text that you want to check\n",
    "        - topk: int -- Your desired truncation of the head of the distribution\n",
    "\n",
    "        Output:\n",
    "        - payload: dict -- The wrapper for results in this function, described below\n",
    "\n",
    "        Payload values\n",
    "        ==============\n",
    "        bpe_strings: list of str -- Each individual token in the text\n",
    "        real_topk: list of tuples -- (ranking, prob) of each token\n",
    "        pred_topk: list of list of tuple -- (word, prob) for all topk\n",
    "        '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def postprocess(self, token):\n",
    "        \"\"\"\n",
    "        clean up the tokens from any special chars and encode\n",
    "        leading space by UTF-8 code '\\u0120', linebreak with UTF-8 code 266 '\\u010A'\n",
    "        :param token:  str -- raw token text\n",
    "        :return: str -- cleaned and re-encoded token text\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def top_k_logits(logits, k):\n",
    "    '''\n",
    "    Filters logits to only the top k choices\n",
    "    from https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py\n",
    "    '''\n",
    "    if k == 0:\n",
    "        return logits\n",
    "    values, _ = torch.topk(logits, k)\n",
    "    min_values = values[:, -1]\n",
    "    return torch.where(logits < min_values,\n",
    "                       torch.ones_like(logits, dtype=logits.dtype) * -1e10,\n",
    "                       logits)\n",
    "\n",
    "\n",
    "class LM(AbstractLanguageChecker):\n",
    "    def __init__(self, model_name_or_path=\"gpt2\"):\n",
    "        super(LM, self).__init__()\n",
    "        self.enc = GPT2Tokenizer.from_pretrained(model_name_or_path)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name_or_path)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.start_token = '<|endoftext|>'\n",
    "        print(\"Loaded GPT-2 model!\")\n",
    "\n",
    "    def check_probabilities(self, in_text, topk=40):\n",
    "        # Process input\n",
    "        start_t = torch.full((1, 1),\n",
    "                             self.enc.encoder[self.start_token],\n",
    "                             device=self.device,\n",
    "                             dtype=torch.long)\n",
    "        context = self.enc.encode(in_text)\n",
    "        context = torch.tensor(context,\n",
    "                               device=self.device,\n",
    "                               dtype=torch.long).unsqueeze(0)\n",
    "        context = torch.cat([start_t, context], dim=1)\n",
    "        # Forward through the model\n",
    "        logits, _ = self.model(context)\n",
    "\n",
    "        # construct target and pred\n",
    "        yhat = torch.softmax(logits[0, :-1], dim=-1)\n",
    "        y = context[0, 1:]\n",
    "        # Sort the predictions for each timestep\n",
    "        sorted_preds = np.argsort(-yhat.data.cpu().numpy())\n",
    "        # [(pos, prob), ...]\n",
    "        real_topk_pos = list(\n",
    "            [int(np.where(sorted_preds[i] == y[i].item())[0][0])\n",
    "             for i in range(y.shape[0])])\n",
    "        real_topk_probs = yhat[np.arange(\n",
    "            0, y.shape[0], 1), y].data.cpu().numpy().tolist()\n",
    "        real_topk_probs = list(map(lambda x: round(x, 5), real_topk_probs))\n",
    "\n",
    "        real_topk = list(zip(real_topk_pos, real_topk_probs))\n",
    "        # [str, str, ...]\n",
    "        bpe_strings = [self.enc.decoder[s.item()] for s in context[0]]\n",
    "\n",
    "        bpe_strings = [self.postprocess(s) for s in bpe_strings]\n",
    "\n",
    "        # [[(pos, prob), ...], [(pos, prob), ..], ...]\n",
    "        pred_topk = [\n",
    "            list(zip([self.enc.decoder[p] for p in sorted_preds[i][:topk]],\n",
    "                     list(map(lambda x: round(x, 5),\n",
    "                              yhat[i][sorted_preds[i][\n",
    "                                      :topk]].data.cpu().numpy().tolist()))))\n",
    "            for i in range(y.shape[0])]\n",
    "\n",
    "        pred_topk = [[(self.postprocess(t[0]), t[1]) for t in pred] for pred in pred_topk]\n",
    "        payload = {'bpe_strings': bpe_strings,\n",
    "                   'real_topk': real_topk,\n",
    "                   'pred_topk': pred_topk}\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return payload\n",
    "\n",
    "    def sample_unconditional(self, length=100, topk=5, temperature=1.0):\n",
    "        '''\n",
    "        Sample `length` words from the model.\n",
    "        Code strongly inspired by\n",
    "        https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_gpt2.py\n",
    "\n",
    "        '''\n",
    "        context = torch.full((1, 1),\n",
    "                             self.enc.encoder[self.start_token],\n",
    "                             device=self.device,\n",
    "                             dtype=torch.long)\n",
    "        prev = context\n",
    "        output = context\n",
    "        past = None\n",
    "        # Forward through the model\n",
    "        with torch.no_grad():\n",
    "            for i in range(length):\n",
    "                logits, past = self.model(prev, past=past)\n",
    "                logits = logits[:, -1, :] / temperature\n",
    "                # Filter predictions to topk and softmax\n",
    "                probs = torch.softmax(top_k_logits(logits, k=topk),\n",
    "                                      dim=-1)\n",
    "                # Sample\n",
    "                prev = torch.multinomial(probs, num_samples=1)\n",
    "                # Construct output\n",
    "                output = torch.cat((output, prev), dim=1)\n",
    "\n",
    "        output_text = self.enc.decode(output[0].tolist())\n",
    "        return output_text\n",
    "\n",
    "    def postprocess(self, token):\n",
    "        with_space = False\n",
    "        with_break = False\n",
    "        if token.startswith('Ġ'):\n",
    "            with_space = True\n",
    "            token = token[1:]\n",
    "            # print(token)\n",
    "        elif token.startswith('â'):\n",
    "            token = ' '\n",
    "        elif token.startswith('Ċ'):\n",
    "            token = ' '\n",
    "            with_break = True\n",
    "\n",
    "        token = '-' if token.startswith('â') else token\n",
    "        token = '“' if token.startswith('ľ') else token\n",
    "        token = '”' if token.startswith('Ŀ') else token\n",
    "        token = \"'\" if token.startswith('Ļ') else token\n",
    "\n",
    "        if with_space:\n",
    "            token = '\\u0120' + token\n",
    "        if with_break:\n",
    "            token = '\\u010A' + token\n",
    "\n",
    "        return token\n",
    "\n",
    "\n",
    "class BERTLM(AbstractLanguageChecker):\n",
    "    def __init__(self, model_name_or_path=\"bert-base-cased\"):\n",
    "        super(BERTLM, self).__init__()\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            do_lower_case=False)\n",
    "        self.model = BertForMaskedLM.from_pretrained(\n",
    "            model_name_or_path)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        # BERT-specific symbols\n",
    "        self.mask_tok = self.tokenizer.convert_tokens_to_ids([\"[MASK]\"])[0]\n",
    "        self.pad = self.tokenizer.convert_tokens_to_ids([\"[PAD]\"])[0]\n",
    "        print(\"Loaded BERT model!\")\n",
    "\n",
    "    def check_probabilities(self, in_text, topk=40, max_context=20,\n",
    "                            batch_size=20):\n",
    "        '''\n",
    "        Same behavior as GPT-2\n",
    "        Extra param: max_context controls how many words should be\n",
    "        fed in left and right\n",
    "        Speeds up inference since BERT requires prediction word by word\n",
    "        '''\n",
    "        in_text = \"[CLS] \" + in_text + \" [SEP]\"\n",
    "        tokenized_text = self.tokenizer.tokenize(in_text)\n",
    "        # Construct target\n",
    "        y_toks = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        # Only use sentence A embedding here since we have non-separable seq's\n",
    "        segments_ids = [0] * len(y_toks)\n",
    "        y = torch.tensor([y_toks]).to(self.device)\n",
    "        segments_tensor = torch.tensor([segments_ids]).to(self.device)\n",
    "\n",
    "        # TODO batching...\n",
    "        # Create batches of (x,y)\n",
    "        input_batches = []\n",
    "        target_batches = []\n",
    "        for min_ix in range(0, len(y_toks), batch_size):\n",
    "            max_ix = min(min_ix + batch_size, len(y_toks) - 1)\n",
    "            cur_input_batch = []\n",
    "            cur_target_batch = []\n",
    "            # Construct each batch\n",
    "            for running_ix in range(max_ix - min_ix):\n",
    "                tokens_tensor = y.clone()\n",
    "                mask_index = min_ix + running_ix\n",
    "                tokens_tensor[0, mask_index + 1] = self.mask_tok\n",
    "\n",
    "                # Reduce computational complexity by subsetting\n",
    "                min_index = max(0, mask_index - max_context)\n",
    "                max_index = min(tokens_tensor.shape[1] - 1,\n",
    "                                mask_index + max_context + 1)\n",
    "\n",
    "                tokens_tensor = tokens_tensor[:, min_index:max_index]\n",
    "                # Add padding\n",
    "                needed_padding = max_context * 2 + 1 - tokens_tensor.shape[1]\n",
    "                if min_index == 0 and max_index == y.shape[1] - 1:\n",
    "                    # Only when input is shorter than max_context\n",
    "                    left_needed = (max_context) - mask_index\n",
    "                    right_needed = needed_padding - left_needed\n",
    "                    p = torch.nn.ConstantPad1d((left_needed, right_needed),\n",
    "                                               self.pad)\n",
    "                    tokens_tensor = p(tokens_tensor)\n",
    "                elif min_index == 0:\n",
    "                    p = torch.nn.ConstantPad1d((needed_padding, 0), self.pad)\n",
    "                    tokens_tensor = p(tokens_tensor)\n",
    "                elif max_index == y.shape[1] - 1:\n",
    "                    p = torch.nn.ConstantPad1d((0, needed_padding), self.pad)\n",
    "                    tokens_tensor = p(tokens_tensor)\n",
    "\n",
    "                cur_input_batch.append(tokens_tensor)\n",
    "                cur_target_batch.append(y[:, mask_index + 1])\n",
    "                # new_segments = segments_tensor[:, min_index:max_index]\n",
    "            cur_input_batch = torch.cat(cur_input_batch, dim=0)\n",
    "            cur_target_batch = torch.cat(cur_target_batch, dim=0)\n",
    "            input_batches.append(cur_input_batch)\n",
    "            target_batches.append(cur_target_batch)\n",
    "\n",
    "        real_topk = []\n",
    "        pred_topk = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for src, tgt in zip(input_batches, target_batches):\n",
    "                # Compute one batch of inputs\n",
    "                # By construction, MASK is always the middle\n",
    "                logits = self.model(src, torch.zeros_like(src))[:,\n",
    "                         max_context + 1]\n",
    "                yhat = torch.softmax(logits, dim=-1)\n",
    "\n",
    "                sorted_preds = np.argsort(-yhat.data.cpu().numpy())\n",
    "                # TODO: compare with batch of tgt\n",
    "\n",
    "                # [(pos, prob), ...]\n",
    "                real_topk_pos = list(\n",
    "                    [int(np.where(sorted_preds[i] == tgt[i].item())[0][0])\n",
    "                     for i in range(yhat.shape[0])])\n",
    "                real_topk_probs = yhat[np.arange(\n",
    "                    0, yhat.shape[0], 1), tgt].data.cpu().numpy().tolist()\n",
    "                real_topk.extend(list(zip(real_topk_pos, real_topk_probs)))\n",
    "\n",
    "                # # [[(pos, prob), ...], [(pos, prob), ..], ...]\n",
    "                pred_topk.extend([list(zip(self.tokenizer.convert_ids_to_tokens(\n",
    "                    sorted_preds[i][:topk]),\n",
    "                    yhat[i][sorted_preds[i][\n",
    "                            :topk]].data.cpu().numpy().tolist()))\n",
    "                    for i in range(yhat.shape[0])])\n",
    "\n",
    "        bpe_strings = [self.postprocess(s) for s in tokenized_text]\n",
    "        pred_topk = [[(self.postprocess(t[0]), t[1]) for t in pred] for pred in pred_topk]\n",
    "        payload = {'bpe_strings': bpe_strings,\n",
    "                   'real_topk': real_topk,\n",
    "                   'pred_topk': pred_topk}\n",
    "        return payload\n",
    "\n",
    "    def postprocess(self, token):\n",
    "\n",
    "        with_space = True\n",
    "        with_break = token == '[SEP]'\n",
    "        if token.startswith('##'):\n",
    "            with_space = False\n",
    "            token = token[2:]\n",
    "\n",
    "        if with_space:\n",
    "            token = '\\u0120' + token\n",
    "        if with_break:\n",
    "            token = '\\u010A' + token\n",
    "        #\n",
    "        # # print ('....', token)\n",
    "        return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(raw_text):\n",
    "    # raw_text = \"\"\"\n",
    "    # In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
    "\n",
    "    # The scientist named the population, after their distinctive horn, Ovid’s Unicorn. These four-horned, silver-white unicorns were previously unknown to science.\n",
    "\n",
    "    # Now, after almost two centuries, the mystery of what sparked this odd phenomenon is finally solved.\n",
    "\n",
    "    # Dr. Jorge Pérez, an evolutionary biologist from the University of La Paz, and several companions, were exploring the Andes Mountains when they found a small valley, with no other animals or humans. Pérez noticed that the valley had what appeared to be a natural fountain, surrounded by two peaks of rock and silver snow.\n",
    "\n",
    "    # Pérez and the others then ventured further into the valley. “By the time we reached the top of one peak, the water looked blue, with some crystals on top,” said Pérez.\n",
    "\n",
    "    # Pérez and his friends were astonished to see the unicorn herd. These creatures could be seen from the air without having to move too much to see them – they were so close they could touch their horns.\n",
    "\n",
    "    # While examining these bizarre creatures the scientists discovered that the creatures also spoke some fairly regular English. Pérez stated, “We can see, for example, that they have a common ‘language,’ something like a dialect or dialectic.”\n",
    "\n",
    "    # Dr. Pérez believes that the unicorns may have originated in Argentina, where the animals were believed to be descendants of a lost race of people who lived there before the arrival of humans in those parts of South America.\n",
    "\n",
    "    # While their origins are still unclear, some believe that perhaps the creatures were created when a human and a unicorn met each other in a time before human civilization. According to Pérez, “In South America, such incidents seem to be quite common.”\n",
    "\n",
    "    # However, Pérez also pointed out that it is likely that the only way of knowing for sure if unicorns are indeed the descendants of a lost alien race is through DNA. “But they seem to be able to communicate in English quite well, which I believe is a sign of evolution, or at least a change in social organization,” said the scientist.\n",
    "    # \"\"\"\n",
    "    # raw_text = \"\"\"\n",
    "    # In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n",
    "    # \"\"\"\n",
    "\n",
    "    \n",
    "    # Tests for BERT\n",
    "    # '''\n",
    "    # lm = BERTLM()\n",
    "    # start = time.time()\n",
    "    # payload = lm.check_probabilities(raw_text, topk=5)\n",
    "    # end = time.time()\n",
    "    # print(\"{:.2f} Seconds for a run with BERT\".format(end - start))\n",
    "    # # print(\"SAMPLE:\", sample)\n",
    "\n",
    "    lm = LM()\n",
    "    start = time.time()\n",
    "    payload = lm.check_probabilities(raw_text, topk=5)\n",
    "    end = time.time()\n",
    "    print(\"{:.2f} Seconds for a check with GPT-2\".format(end - start))\n",
    "\n",
    "    start = time.time()\n",
    "    sample = lm.sample_unconditional()\n",
    "    end = time.time()\n",
    "    print(\"{:.2f} Seconds for a sample from GPT-2\".format(end - start))\n",
    "    print(\"SAMPLE:\", sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To check the smoothness of a text, I will plot the rank of every word. If the ranks of words in a text are higher, the text will be unsmooth according to the GPT-2 Language Model. Following code is used to create these plots for texts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/HendrikStrobelt/detecting-fake-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_text(vals, what, name):\n",
    "    if what==\"prob\":\n",
    "        ourvals = vals[0]\n",
    "        x = list(range(1,len(ourvals)+1))\n",
    "        y = ourvals\n",
    "        plt.plot(x, y, color='orange')\n",
    "        plt.ylim(0,1)\n",
    "        plt.savefig(name + \".png\")\n",
    "        # plt.show()\n",
    "    elif what==\"rank\":\n",
    "        ourvals = vals[1]\n",
    "        x = list(range(1, len(ourvals) + 1))\n",
    "        y = ourvals\n",
    "        plt.plot(x, y, color='orange')\n",
    "        plt.ylim(-1000, 50000)\n",
    "        plt.savefig(name + \".png\")\n",
    "        # plt.show()\n",
    "def main_code(raw_text):\n",
    "    lm = LM()\n",
    "    start = time.time()\n",
    "    payload = lm.check_probabilities(raw_text, topk=5)\n",
    "    # print(payload[\"pred_topk\"])\n",
    "    real_topK = payload[\"real_topk\"]\n",
    "    ranks = [i[0] for i in real_topK]\n",
    "    preds = [i[1] for i in real_topK]\n",
    "    plot_text([preds, ranks], 'rank', \"rank_\")\n",
    "    end = time.time()\n",
    "    print(\"{:.2f} Seconds for a check with GPT-2\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "realExample = \"I can see you over there Starring at your drink Watchin' that ice sink All alone tonightAnd chances are You're sittin' here in this bar 'Cause he ain't gonna treat you right Well, it's probably not my place But I'm gonna say it anyway 'Cause you look like You haven't felt the fire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatedExample =\"well it's probably not my place but i'm gonna say it anyway 'cause you look like you haven't felt the fire had a little fun hadn't had a smile in a little red honda and headed straight for the pier tank top and cutoff jeans a little pac sun underneath who knew it was 'bout and he said some day i hope you think of me and i'm back on all of that it's nice to believe when you think tim mcgraw i hope you think of me and i'm back on all of that it's nice to believe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GPT-2 model!\n",
      "0.65 Seconds for a check with GPT-2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_code(realExample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GPT-2 model!\n",
      "0.99 Seconds for a check with GPT-2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_code(generatedExample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
